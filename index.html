<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Avatar</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
  <div id="learning"></div>
  <div id="avatar"></div>

  <div id="assesment">
    <h1>AI TEACHER</h1>
    <p>Here is the summarized text for your uploaded content!</p>
      <p>HAPPY LEARNING!<br><br></p>
  </div>

  <div id="controls">
      <div id="speak" type="button" value="Ask me">Ask Me</div>
      <div id="avatarButton1" class="button">Avatar 1</div>
      <div id="avatarButton2" class="button">Avatar 2</div>
  </div>
  <div id="take-assesment">Take Assesment</div>
    <div id="loading"></div>
  <div>
    <button id="startButton">Start Speaking</button>
  </div>
  <!-- Correct Three.js and related libraries -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/three@0.128.0/examples/js/controls/OrbitControls.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/three@0.128.0/examples/js/loaders/GLTFLoader.js"></script>

    <script>
      let scene, camera, renderer, avatar;
      let mouthOpenIndex = null;
      let isSpeaking = false;
      let currentAnimation = null;

      // Predefined text to speak
      const speechText = `Hello! I am your virtual avatar.`;

      function init() {
          scene = new THREE.Scene();
          camera = new THREE.PerspectiveCamera(30, window.innerWidth / window.innerHeight, 0.1, 1000);
          camera.position.set(0, 1.1, 5.5);

          renderer = new THREE.WebGLRenderer({ 
              antialias: true,
              alpha: true  // Add this line to enable transparency
          });
          renderer.setSize(window.innerWidth, window.innerHeight);
          // renderer.setClearColor(0xf0f0f0);  // Remove or comment out this line
          document.body.appendChild(renderer.domElement);

          // Create controls
          const controls = new THREE.OrbitControls(camera, renderer.domElement);
          controls.enableDamping = true;
          controls.dampingFactor = 0.25;
          controls.enableZoom = false;
          controls.enableRotate = false;
          controls.enablePan = false;

          // Lighting
          const ambientLight = new THREE.AmbientLight(0xffffff, 1);
          scene.add(ambientLight);

          const directionalLight = new THREE.DirectionalLight(0xffffff, 0.8);
          directionalLight.position.set(2, 5, 7.5);
          scene.add(directionalLight);

          loadAvatar();
          animate();

          window.addEventListener('resize', onWindowResize, false);
      }

      function onWindowResize() {
          camera.aspect = window.innerWidth / window.innerHeight;
          camera.updateProjectionMatrix();
          renderer.setSize(window.innerWidth, window.innerHeight);
      }

      function loadAvatar() {
          const loader = new THREE.GLTFLoader();
          const avatarUrl = 'https://models.readyplayer.me/6738baadbdc370b5cbbaba87.glb';

          loader.load(
              avatarUrl,
              (gltf) => {
                  avatar = gltf.scene;
                  scene.add(avatar);

                  avatar.position.set(1, -6.3, 0);
                  avatar.rotation.y = -0.2;
                  avatar.scale.set(4, 4, 2);

                  avatar.traverse((child) => {
                      if (child.isMesh && child.morphTargetDictionary) {
                          console.log('Available Blend Shapes:', child.morphTargetDictionary);
                          mouthOpenIndex = child.morphTargetDictionary['mouthOpen'];
                      }
                  });

                  setupSpeechButton();
              },
              undefined,
              (error) => console.error('Error loading avatar:', error)
          );
      }

      function animate() {
          requestAnimationFrame(animate);
          renderer.render(scene, camera);
      }

      function setupSpeechButton() {
          const startButton = document.getElementById('startButton');
          startButton.addEventListener('click', () => {
              if (isSpeaking) {
                  stopSpeaking();
              } else {
                  startSpeaking();
              }
          });
      }

      function startSpeaking() {
          if (!window.speechSynthesis) {
              alert('Speech Synthesis API is not supported in this browser.');
              return;
          }

          const startButton = document.getElementById('startButton');
          startButton.textContent = 'Stop Speaking';
          isSpeaking = true;

          const speech = new SpeechSynthesisUtterance(speechText);
          speech.rate = 0.9;  // Slightly slower for clarity
          speech.pitch = 1.1; // Slightly higher pitch
          speech.volume = 1;

          let lastMouthValue = 0;
          const mouthSpeed = 0.15;

          function updateMouth() {
              if (!isSpeaking) return;

              avatar.traverse((child) => {
                  if (child.isMesh && child.morphTargetInfluences && mouthOpenIndex !== null) {
                      // Natural mouth movement
                      const targetValue = Math.random() * 0.8;
                      const oscillation = Math.sin(Date.now() * 0.01) * 0.1;
                      lastMouthValue += (targetValue - lastMouthValue) * mouthSpeed;
                      child.morphTargetInfluences[mouthOpenIndex] = lastMouthValue + oscillation;
                  }
              });

              currentAnimation = requestAnimationFrame(updateMouth);
          }

          speech.onstart = () => {
              updateMouth();
          };

          speech.onend = () => {
              stopSpeaking();
          };

          speech.onerror = (event) => {
              console.error('Speech synthesis error:', event);
              stopSpeaking();
          };

          window.speechSynthesis.speak(speech);
      }

      function stopSpeaking() {
          isSpeaking = false;
          window.speechSynthesis.cancel();
          
          if (currentAnimation) {
              cancelAnimationFrame(currentAnimation);
          }

          avatar.traverse((child) => {
              if (child.isMesh && child.morphTargetInfluences && mouthOpenIndex !== null) {
                  child.morphTargetInfluences[mouthOpenIndex] = 0;
              }
          });

          const startButton = document.getElementById('startButton');
          startButton.textContent = 'Start Speaking';
      }

      init();
  </script>
    <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/axios/dist/axios.min.js"></script>
    <script type="module" src="index.js"></script>
    
</body>
</html>
